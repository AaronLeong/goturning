{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.misc import imread\n",
    "\n",
    "import caffe_classes\n",
    "\n",
    "# TODO: make TensforFlow v1.0 both compatible and a requirement\n",
    "if tf.__version__ < '0.12.0':\n",
    "    print('Validated only for TensorFlow v0.12')\n",
    "if tf.__version__ >= '1.0.0':\n",
    "    raise BaseException('TensorFlow v1.0 likely requires parameter reordering => https://groups.google.com/a/tensorflow.org/forum/#!msg/discuss/OePXmC9kJ7o/SRErOoYCDQAJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RGB2BGR(img):\n",
    "    img2 = img.copy()\n",
    "    img2[:, :, 0], img2[:, :, 2] = img2[:, :, 2], img2[:, :, 0]\n",
    "    return img2\n",
    "\n",
    "def load_preprocess_img(fname):\n",
    "    img = imread(fname)[:,:,:3].astype(np.float32)\n",
    "    img - np.mean(img)\n",
    "    RGB2BGR(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_names = ['dog.png', 'dog.png', 'laska.png', 'poodle.png', 'quail227.JPEG']\n",
    "images = []\n",
    "for image_name in image_names:\n",
    "    images.append(load_preprocess_img('tmp/training_data/alexnet/' + image_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net_data = np.load(open(\"tmp/training_data/alexnet/bvlc_alexnet.npy\", \"rb\"), encoding=\"latin1\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/guerzh/tf_weights/blob/master/myalexnet_forward_newtf.py#L73\n",
    "# https://github.com/ethereon/caffe-tensorflow/blob/master/kaffe/tensorflow/network.py#L105\n",
    "\n",
    "def conv(input, kernel, biases, c_o, stride_h, stride_w,  padding=\"VALID\", group=1):\n",
    "    c_i = input.get_shape()[-1]\n",
    "    assert c_i % group == 0\n",
    "    assert c_o % group == 0\n",
    "    convolve = lambda i, k: tf.nn.conv2d(i, k, [1, stride_h, stride_w, 1], padding=padding)\n",
    "    \n",
    "    if group==1:\n",
    "        conv = convolve(input, kernel)\n",
    "    else:\n",
    "        input_groups =  tf.split(3, group, input)   #tf.split(3, group, input)\n",
    "        kernel_groups = tf.split(3, group, kernel)   #tf.split(3, group, kernel) \n",
    "        output_groups = [convolve(i, k) for i,k in zip(input_groups, kernel_groups)]\n",
    "        conv = tf.concat(3, output_groups)          #tf.concat(3, output_groups)\n",
    "    return  tf.reshape(tf.nn.bias_add(conv, biases), [-1]+conv.get_shape().as_list()[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Heavily modified from: https://github.com/guerzh/tf_weights/blob/master/myalexnet_forward_newtf.py#L93\n",
    "# TODO: should be shared tf.Variable rather than copying them for each alexnet\n",
    "\n",
    "def alexnet(net_data):\n",
    "    \"\"\"Creates AlexNet TensorFlow graph with weights. Returns input placeholder, maxpool5 and softmax outputs.\"\"\"\n",
    "    x = tf.placeholder(tf.float32, (None, 227, 227, 3))\n",
    "\n",
    "    #conv1\n",
    "    #conv(11, 11, 96, 4, 4, padding='VALID', name='conv1')\n",
    "    k_h = 11; k_w = 11; c_o = 96; s_h = 4; s_w = 4\n",
    "    conv1W = tf.Variable(net_data[\"conv1\"][0], trainable=False)\n",
    "    conv1b = tf.Variable(net_data[\"conv1\"][1], trainable=False)\n",
    "    conv1_in = conv(x, conv1W, conv1b, c_o, s_h, s_w, padding=\"SAME\", group=1)\n",
    "    conv1 = tf.nn.relu(conv1_in)\n",
    "\n",
    "    #lrn1\n",
    "    #lrn(2, 2e-05, 0.75, name='norm1')\n",
    "    radius = 2; alpha = 2e-05; beta = 0.75; bias = 1.0\n",
    "    lrn1 = tf.nn.local_response_normalization(conv1,\n",
    "                                              depth_radius=radius,\n",
    "                                              alpha=alpha,\n",
    "                                              beta=beta,\n",
    "                                              bias=bias)\n",
    "\n",
    "    #maxpool1\n",
    "    #max_pool(3, 3, 2, 2, padding='VALID', name='pool1')\n",
    "    k_h = 3; k_w = 3; s_h = 2; s_w = 2; padding = 'VALID'\n",
    "    maxpool1 = tf.nn.max_pool(lrn1, ksize=[1, k_h, k_w, 1], strides=[1, s_h, s_w, 1], padding=padding)\n",
    "\n",
    "    #conv2\n",
    "    #conv(5, 5, 256, 1, 1, group=2, name='conv2')\n",
    "    k_h = 5; k_w = 5; c_o = 256; s_h = 1; s_w = 1; group = 2\n",
    "    conv2W = tf.Variable(net_data[\"conv2\"][0], trainable=False)\n",
    "    conv2b = tf.Variable(net_data[\"conv2\"][1], trainable=False)\n",
    "    conv2_in = conv(maxpool1, conv2W, conv2b, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
    "    conv2 = tf.nn.relu(conv2_in)\n",
    "\n",
    "    #lrn2\n",
    "    #lrn(2, 2e-05, 0.75, name='norm2')\n",
    "    radius = 2; alpha = 2e-05; beta = 0.75; bias = 1.0\n",
    "    lrn2 = tf.nn.local_response_normalization(\n",
    "        conv2,\n",
    "        depth_radius=radius,\n",
    "        alpha=alpha,\n",
    "        beta=beta,\n",
    "        bias=bias)\n",
    "\n",
    "    #maxpool2\n",
    "    #max_pool(3, 3, 2, 2, padding='VALID', name='pool2')                                                  \n",
    "    k_h = 3; k_w = 3; s_h = 2; s_w = 2; padding = 'VALID'\n",
    "    maxpool2 = tf.nn.max_pool(lrn2, ksize=[1, k_h, k_w, 1], strides=[1, s_h, s_w, 1], padding=padding)\n",
    "\n",
    "    #conv3\n",
    "    #conv(3, 3, 384, 1, 1, name='conv3')\n",
    "    k_h = 3; k_w = 3; c_o = 384; s_h = 1; s_w = 1; group = 1\n",
    "    conv3W = tf.Variable(net_data[\"conv3\"][0], trainable=False)\n",
    "    conv3b = tf.Variable(net_data[\"conv3\"][1], trainable=False)\n",
    "    conv3_in = conv(maxpool2, conv3W, conv3b, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
    "    conv3 = tf.nn.relu(conv3_in)\n",
    "\n",
    "    #conv4\n",
    "    #conv(3, 3, 384, 1, 1, group=2, name='conv4')\n",
    "    k_h = 3; k_w = 3; c_o = 384; s_h = 1; s_w = 1; group = 2\n",
    "    conv4W = tf.Variable(net_data[\"conv4\"][0], trainable=False)\n",
    "    conv4b = tf.Variable(net_data[\"conv4\"][1], trainable=False)\n",
    "    conv4_in = conv(conv3, conv4W, conv4b, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
    "    conv4 = tf.nn.relu(conv4_in)\n",
    "\n",
    "    #conv5\n",
    "    #conv(3, 3, 256, 1, 1, group=2, name='conv5')\n",
    "    k_h = 3; k_w = 3; c_o = 256; s_h = 1; s_w = 1; group = 2\n",
    "    conv5W = tf.Variable(net_data[\"conv5\"][0], trainable=False)\n",
    "    conv5b = tf.Variable(net_data[\"conv5\"][1], trainable=False)\n",
    "    conv5_in = conv(conv4, conv5W, conv5b, c_o, s_h, s_w, padding=\"SAME\", group=group)\n",
    "    conv5 = tf.nn.relu(conv5_in)\n",
    "\n",
    "    #maxpool5\n",
    "    #max_pool(3, 3, 2, 2, padding='VALID', name='pool5')\n",
    "    k_h = 3; k_w = 3; s_h = 2; s_w = 2; padding = 'VALID'\n",
    "    maxpool5 = tf.nn.max_pool(conv5, ksize=[1, k_h, k_w, 1], strides=[1, s_h, s_w, 1], padding=padding)\n",
    "\n",
    "    #fc6_alexnet\n",
    "    #fc(4096, name='fc6')\n",
    "    fc6W = tf.Variable(net_data[\"fc6\"][0])\n",
    "    fc6b = tf.Variable(net_data[\"fc6\"][1])\n",
    "    fc6 = tf.nn.relu_layer(tf.reshape(maxpool5, [-1, int(np.prod(maxpool5.get_shape()[1:]))]), fc6W, fc6b)\n",
    "\n",
    "    #fc7_alexnet\n",
    "    #fc(4096, name='fc7')\n",
    "    fc7W = tf.Variable(net_data[\"fc7\"][0])\n",
    "    fc7b = tf.Variable(net_data[\"fc7\"][1])\n",
    "    fc7 = tf.nn.relu_layer(fc6, fc7W, fc7b)\n",
    "\n",
    "    #fc8_alexnet\n",
    "    #fc(1000, relu=False, name='fc8')\n",
    "    fc8W = tf.Variable(net_data[\"fc8\"][0])\n",
    "    fc8b = tf.Variable(net_data[\"fc8\"][1])\n",
    "    fc8 = tf.nn.xw_plus_b(fc7, fc8W, fc8b)\n",
    "\n",
    "    #prob_alexnet\n",
    "    #softmax(name='prob'))\n",
    "    softmax = tf.nn.softmax(fc8)\n",
    "\n",
    "    return x, maxpool5, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image: dog.png\n",
      "flat-coated retriever 0.475118\n",
      "Newfoundland, Newfoundland dog 0.159941\n",
      "Tibetan mastiff 0.115989\n",
      "standard poodle 0.0608109\n",
      "Afghan hound, Afghan 0.0281317\n",
      "\n",
      "Image: dog.png\n",
      "flat-coated retriever 0.475118\n",
      "Newfoundland, Newfoundland dog 0.159941\n",
      "Tibetan mastiff 0.115989\n",
      "standard poodle 0.0608109\n",
      "Afghan hound, Afghan 0.0281317\n",
      "\n",
      "Image: laska.png\n",
      "weasel 0.257096\n",
      "polecat, fitch, foulmart, foumart, Mustela putorius 0.170497\n",
      "black-footed ferret, ferret, Mustela nigripes 0.124212\n",
      "llama 0.106355\n",
      "Arctic fox, white fox, Alopex lagopus 0.0829945\n",
      "\n",
      "Image: poodle.png\n",
      "komondor 0.244168\n",
      "miniature poodle 0.204217\n",
      "toy poodle 0.112967\n",
      "Bedlington terrier 0.106496\n",
      "standard poodle 0.0961162\n",
      "\n",
      "Image: quail227.JPEG\n",
      "water ouzel, dipper 0.489476\n",
      "quail 0.188902\n",
      "hummingbird 0.0747858\n",
      "chickadee 0.0405761\n",
      "American egret, great white heron, Egretta albus 0.0277748\n"
     ]
    }
   ],
   "source": [
    "x, maxpool5, softmax = alexnet(net_data)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "output = sess.run(softmax, feed_dict = {x:images})\n",
    "\n",
    "for image_idx in range(output.shape[0]):\n",
    "    inds = np.argsort(output)[image_idx,:]\n",
    "    print('')\n",
    "    print('Image: ' + image_names[image_idx])\n",
    "    for i in range(5):\n",
    "        print(caffe_classes.class_names[inds[-1-i]], output[image_idx, inds[-1-i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def goturn_model(net_data):\n",
    "    x0, caffe0, _ = alexnet(net_data)\n",
    "    x1, caffe1, _ = alexnet(net_data)\n",
    "\n",
    "    merged = tf.concat(1, (caffe0, caffe1))\n",
    "    \n",
    "    #fc6_goturn\n",
    "    #fc(4096, name='fc6')\n",
    "    new_shape = int(np.prod(merged.get_shape()[1:]))\n",
    "\n",
    "    fc6W = tf.Variable(tf.truncated_normal((new_shape, 4096), stddev=0.1))\n",
    "    fc6b = tf.Variable(tf.truncated_normal((4096,), stddev=0.1))\n",
    "    fc6 = tf.nn.relu_layer(tf.reshape(merged, [-1, new_shape]), fc6W, fc6b)\n",
    "\n",
    "    #fc7_goturn\n",
    "    #fc(4096, name='fc7')\n",
    "    fc7W = tf.Variable(tf.truncated_normal((4096, 4096), stddev=0.1))\n",
    "    fc7b = tf.Variable(tf.truncated_normal((4096,), stddev=0.1))\n",
    "    fc7 = tf.nn.relu_layer(fc6, fc7W, fc7b)\n",
    "\n",
    "    #bbox_goturn\n",
    "    #fc(4, relu=False, name='fc8')\n",
    "    fc8W = tf.Variable(tf.truncated_normal((4096, 4), stddev=0.1))\n",
    "    fc8b = tf.Variable(tf.truncated_normal((4,), stddev=0.1))\n",
    "    bbox = tf.nn.xw_plus_b(fc7, fc8W, fc8b)\n",
    "    \n",
    "    return x0, x1, bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loss(y_true, y_pred):\n",
    "    # GOTURN uses L1 loss function to promote tighter bounding boxes compared to L2 mean\n",
    "    loss = tf.reduce_mean(tf.abs(y_true - y_pred))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('tmp/generated/vot/map_all.csv')[:300]\n",
    "list_train, list_test = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 6 columns):\n",
      "file1    300 non-null object\n",
      "file2    300 non-null object\n",
      "bbtlx    300 non-null float64\n",
      "bblry    300 non-null float64\n",
      "bbbrx    300 non-null float64\n",
      "bbbry    300 non-null float64\n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 14.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_image_tensor(df):\n",
    "    t0 = [load_preprocess_img(i) for i in df['file1']]\n",
    "    t1 = [load_preprocess_img(i) for i in df['file2']]\n",
    "    return np.array(t0), np.array(t1), df[df.columns[2:]].values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train0, X_train1, y_train = get_image_tensor(list_train)\n",
    "X_test0, X_test1, y_test = get_image_tensor(list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 227, 227, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(learn_rate=0.01, batch_size=3, initial_weights=net_data):\n",
    "\n",
    "    x0, x1, y_pred = goturn_model(initial_weights)\n",
    "    y_true = tf.placeholder(tf.float32, (None, 4))\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    loss = get_loss(y_true, y_pred)\n",
    "    train_step = tf.train.AdamOptimizer(learn_rate).minimize(loss)\n",
    "\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.95)\n",
    "    with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        for i in range(int(len(X_train0)/batch_size) - 1):\n",
    "            start = i*batch_size\n",
    "            end = i*(batch_size+1)\n",
    "            batch_x0s = X_train0[start:end]\n",
    "            batch_x1s = X_train1[start:end]\n",
    "            batch_ys = y_train[start:end]\n",
    "\n",
    "            sess.run(train_step, feed_dict={x0: batch_x0s,\n",
    "                                            x1: batch_x1s,\n",
    "                                            y_true: batch_ys})\n",
    "            print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
